

# features
# parallel actor
# parallel learner
#   for bc
#   for off-policy RL
# parallel recording

# datatsets and policies should be usable with lerobot_train

# single primitive wrapper

# everything works via environments
# robots and teleoperators can be dictionaries
# environments define their own make and processors









# Copyright 2024 The HuggingFace Inc. team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Records a dataset. Actions for the robot can be either generated by teleoperation or by a policy.

Example:

```shell
lerobot-record \
    --robot.type=so100_follower \
    --robot.port=/dev/tty.usbmodem58760431541 \
    --robot.cameras="{laptop: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}}" \
    --robot.id=black \
    --dataset.repo_id=<my_username>/<my_dataset_name> \
    --dataset.num_episodes=2 \
    --dataset.single_task="Grab the cube" \
    --display_data=true
    # <- Teleop optional if you want to teleoperate to record or in between episodes with a policy \
    # --teleop.type=so100_leader \
    # --teleop.port=/dev/tty.usbmodem58760431551 \
    # --teleop.id=blue \
    # <- Policy optional if you want to record with a policy \
    # --policy.path=${HF_USER}/my_policy \
```

Example recording with bimanual so100:
```shell
lerobot-record \
  --robot.type=bi_so100_follower \
  --robot.left_arm_port=/dev/tty.usbmodem5A460851411 \
  --robot.right_arm_port=/dev/tty.usbmodem5A460812391 \
  --robot.id=bimanual_follower \
  --robot.cameras='{
    left: {"type": "opencv", "index_or_path": 0, "width": 640, "height": 480, "fps": 30},
    top: {"type": "opencv", "index_or_path": 1, "width": 640, "height": 480, "fps": 30},
    right: {"type": "opencv", "index_or_path": 2, "width": 640, "height": 480, "fps": 30}
  }' \
  --teleop.type=bi_so100_leader \
  --teleop.left_arm_port=/dev/tty.usbmodem5A460828611 \
  --teleop.right_arm_port=/dev/tty.usbmodem5A460826981 \
  --teleop.id=bimanual_leader \
  --display_data=true \
  --dataset.repo_id=${HF_USER}/bimanual-so100-handover-cube \
  --dataset.num_episodes=25 \
  --dataset.single_task="Grab and handover the red cube to the other arm"
```
"""

import logging
from contextlib import nullcontext
import time
from dataclasses import asdict
from pprint import pformat
from typing import Any

import numpy as np
import torch

from lerobot.cameras.opencv.configuration_opencv import OpenCVCameraConfig  # noqa: F401
from lerobot.cameras.realsense.configuration_realsense import RealSenseCameraConfig  # noqa: F401
from lerobot.configs import parser
from lerobot.datasets.image_writer import safe_stop_image_writer
from lerobot.datasets.lerobot_dataset import LeRobotDataset
from lerobot.datasets.video_utils import VideoEncodingManager
from lerobot.envs.robot_env import RobotEnv
from lerobot.policies.factory import make_policy, make_pre_post_processors
from lerobot.policies.pretrained import PreTrainedPolicy
from lerobot.processor import (
    PolicyAction,
    PolicyProcessorPipeline,
    RobotProcessorPipeline,
    create_transition,
    TransitionKey,
)
from lerobot.processor.hil_processor import TELEOP_ACTION_KEY
from lerobot.processor.rename_processor import rename_stats
from lerobot.share.configs import RecordConfig
from lerobot.teleoperators import Teleoperator, TeleopEvents
from lerobot.utils.constants import ACTION, REWARD, DONE
from lerobot.utils.control_utils import (
    predict_action,
    sanity_check_dataset_name,
    sanity_check_dataset_robot_compatibility,
)
from lerobot.utils.robot_utils import busy_wait
from lerobot.utils.transition import Transition
from lerobot.utils.utils import (
    get_safe_torch_device,
    init_logging,
    log_say,
)
from lerobot.utils.visualization_utils import init_rerun, log_rerun_data
from lerobot.share.utils import get_pipeline_dataset_features


""" --------------- record_loop() data flow --------------------------
       [ Robot ]
           V
     [ robot.get_observation() ] ---> raw_obs
           V
     [ robot_observation_processor ] ---> processed_obs
           V
     .-----( ACTION LOGIC )------------------.
     V                                       V
     [ From Teleoperator ]                   [ From Policy ]
     |                                       |
     |  [teleop.get_action] -> raw_action    |   [predict_action]
     |          |                            |          |
     |          V                            |          V
     | [teleop_action_processor]             |          |
     |          |                            |          |
     '---> processed_teleop_action           '---> processed_policy_action
     |                                       |
     '-------------------------.-------------'
                               V
                  [ robot_action_processor ] --> robot_action_to_send
                               V
                    [ robot.send_action() ] -- (Robot Executes)
                               V
                    ( Save to Dataset )
                               V
                  ( Rerun Log / Loop Wait )
"""


@safe_stop_image_writer
def record_loop(
    env: RobotEnv,
    fps: int,
    action_dim: int,
    action_processor: RobotProcessorPipeline[Transition, Transition],
    env_processor: RobotProcessorPipeline[Transition, Transition],
    dataset: LeRobotDataset | None = None,
    policy: PreTrainedPolicy | None = None,
    preprocessor: PolicyProcessorPipeline[dict[str, Any], dict[str, Any]] | None = None,
    postprocessor: PolicyProcessorPipeline[PolicyAction, PolicyAction] | None = None,
    control_time_s: float | None = None,
    single_task: str | None = None,
    robot_type: str| None = None,
    display_data: bool = False,
    device: str = "cuda",
    use_amp: bool = False,
    interactive: bool = False
):
    if control_time_s is None:
        control_time_s = float("inf")

    if dataset is not None and dataset.fps != fps:
        raise ValueError(f"The dataset fps should be equal to requested fps ({dataset.fps} != {fps}).")

    has_policy = policy is not None and preprocessor is not None and postprocessor is not None
    teleoperate = not has_policy
    assert not interactive or has_policy, "Interactive recording requires a policy."

    # Reset policy and processor if they are provided
    if policy is not None and preprocessor is not None and postprocessor is not None:
        policy.reset()
        preprocessor.reset()
        postprocessor.reset()

    obs, info = env.reset()
    env_processor.reset()
    action_processor.reset()

    # Process initial observation
    transition = create_transition(observation=obs, info=info)
    transition = env_processor(data=transition)  # outputs valid transition

    intervention_occurred = False
    info: dict = transition[TransitionKey.INFO]
    episode_step = 0
    episode_start_time = time.perf_counter()
    while (time.perf_counter() - episode_start_time) < control_time_s:
        start_loop_t = time.perf_counter()

        # (1) Keep the PRE-STEP transition (this holds o_t) and reset info dict
        prev_transition = transition
        info = {}

        # (2) Handle intervention control flow
        if teleoperate:
            # Permanently set the intervention flag to stay in control
            info[TeleopEvents.IS_INTERVENTION] = True

        # (3) Decide and process action a_t
        if has_policy:
            policy_observation = {
                k: v for k, v in prev_transition[TransitionKey.OBSERVATION].items() if k in policy.config.input_features
            }
            # noinspection PyTypeChecker
            action = predict_action(
                observation=policy_observation,
                policy=policy,
                device=get_safe_torch_device(device),
                preprocessor=preprocessor,
                postprocessor=postprocessor,
                use_amp=use_amp,
                task=single_task,
                robot_type=robot_type
            )
        else:
            # Dummy action, expected to be overwritten by teleop action
            action = torch.tensor([0.0] * action_dim, dtype=torch.float32)

        # Process action
        action_transition = create_transition(action=action, info=info)
        processed_action_transition = action_processor(action_transition)

        if processed_action_transition.get(TransitionKey.DONE, False):
            info.update(processed_action_transition[TransitionKey.INFO].copy())
            episode_time = time.perf_counter() - episode_start_time
            logging.info(
                f"Intervention ended after {episode_step} steps in {episode_time:.1f}s with reward {transition[TransitionKey.REWARD]}"
            )
            return info

        # (5) Step env
        obs, reward, terminated, truncated, info = env.step(processed_action_transition[TransitionKey.ACTION])

        # (6) Read out info and possibly overwrite action
        complementary_data = processed_action_transition[TransitionKey.COMPLEMENTARY_DATA].copy()
        info.update(processed_action_transition[TransitionKey.INFO].copy())

        # determine which action to store
        if info.get(TeleopEvents.IS_INTERVENTION, False) and TELEOP_ACTION_KEY in complementary_data:
            action_to_record = complementary_data[TELEOP_ACTION_KEY]
        else:
            action_to_record = action_transition[TransitionKey.ACTION]

        # (7) Create and process transition
        transition = create_transition(
            observation=obs,
            action=action_to_record,
            reward=reward + processed_action_transition[TransitionKey.REWARD],
            done=terminated or processed_action_transition[TransitionKey.DONE],
            truncated=truncated or processed_action_transition[TransitionKey.TRUNCATED],
            info=info,
            complementary_data=processed_action_transition[TransitionKey.COMPLEMENTARY_DATA].copy(),
        )
        transition = env_processor(transition)

        action = transition[TransitionKey.ACTION]
        reward = transition[TransitionKey.REWARD]
        terminated = transition.get(TransitionKey.DONE, False)
        truncated = transition.get(TransitionKey.TRUNCATED, False)
        info = transition.get(TransitionKey.INFO, {})

        # (8) Store transition. When interactive, only store frames on interventions
        if dataset is not None and (not interactive or info.get(TeleopEvents.IS_INTERVENTION, False)):

            # observations are batched and may contain other keys
            dataset_observation = {
                k: v.squeeze().cpu()
                for k, v in prev_transition[TransitionKey.OBSERVATION].items()
                if k in dataset.features
            }

            # store frame
            frame = {
                **dataset_observation,
                ACTION: action.squeeze().cpu(),
                REWARD: np.array([reward], dtype=np.float32),
                DONE: np.array([terminated or truncated], dtype=bool),
                "task": single_task
            }
            dataset.add_frame(frame)

            if display_data:
                rerun_obs = {k: v.numpy() for k, v in dataset_observation.items()}
                log_rerun_data(observation=rerun_obs, action=action)

        episode_step += 1

        # (9) Handle done
        if terminated or truncated:
            episode_time = time.perf_counter() - episode_start_time
            logging.info(
                f"Episode ended after {episode_step} steps in {episode_time:.1f}s with reward {transition[TransitionKey.REWARD]}"
            )
            return info

        if info.get(TeleopEvents.RERECORD_EPISODE, False) or info.get(TeleopEvents.TERMINATE_EPISODE, False):
            return info

        # (10) Handle frequency
        dt_load = time.perf_counter() - start_loop_t
        busy_wait(1 / fps - dt_load)
        dt_loop = time.perf_counter() - start_loop_t
        logging.info(
            f"dt_load: {dt_loop * 1000:5.2f}ms ({1 / dt_loop:3.1f}hz), "
            f"dt_load: {dt_load * 1000:5.2f}ms ({1 / dt_load:3.1f}hz)"
        )

    else:
        return info

@parser.wrap()
def record(cfg: RecordConfig) -> LeRobotDataset | None:
    init_logging()
    logging.info(pformat(asdict(cfg)))
    if cfg.display_data:
        init_rerun(session_name="recording")

    env, env_processor, action_processor = cfg.env.make(device="cpu" if cfg.policy is None else cfg.policy.device)

    dataset_features = get_pipeline_dataset_features(env, env_processor, action_dim=cfg.env.action_dim, use_video=cfg.dataset.video)

    teleop_on_reset = cfg.env.processor.reset.teleop_on_reset if hasattr(cfg.env, "processor") else False

    # Demo mode: do not create any dataset
    dataset: LeRobotDataset | None
    if getattr(cfg, "demo_mode", False):
        dataset = None
    else:
        if cfg.resume:
            dataset = LeRobotDataset(
                cfg.dataset.repo_id,
                root=cfg.dataset.root,
                batch_encoding_size=cfg.dataset.video_encoding_batch_size,
            )

            if hasattr(env, "cameras") and len(env.cameras) > 0:
                dataset.start_image_writer(
                    num_processes=cfg.dataset.num_image_writer_processes,
                    num_threads=cfg.dataset.num_image_writer_threads_per_camera * len(env.cameras),
                )
            sanity_check_dataset_robot_compatibility(dataset, cfg.env.type, cfg.dataset.fps, dataset_features)
        else:
            # Create empty dataset or load existing saved episodes
            sanity_check_dataset_name(cfg.dataset.repo_id, cfg.policy)
            dataset = LeRobotDataset.create(
                cfg.dataset.repo_id,
                cfg.dataset.fps,
                root=cfg.dataset.root,
                robot_type=cfg.env.type,
                features=dataset_features,
                use_videos=cfg.dataset.video,
                image_writer_processes=cfg.dataset.num_image_writer_processes,
                image_writer_threads=cfg.dataset.num_image_writer_threads_per_camera * len(cfg.env.cameras),
                batch_encoding_size=cfg.dataset.video_encoding_batch_size,
            )

    # Load pretrained policy
    if cfg.policy is None:
        policy = None
    else:
        if dataset is None:
            # Demo mode: dataset is absent. We need policy input/output features.
            # Instead of relying on env_cfg.features (empty for real robot env configs),
            # synthesize minimal dataset metadata from pipeline-derived dataset_features.
            class _SyntheticMeta:
                def __init__(self, features: dict[str, dict]):
                    self.features = features
            synthetic_meta = _SyntheticMeta(dataset_features)
            policy = make_policy(cfg.policy, ds_meta=synthetic_meta)
        else:
            policy = make_policy(cfg.policy, ds_meta=dataset.meta)
    preprocessor = None
    postprocessor = None
    if cfg.policy is not None:
        if dataset is None:
            preprocessor, postprocessor = make_pre_post_processors(
                policy_cfg=cfg.policy,
                pretrained_path=cfg.policy.pretrained_path,
                preprocessor_overrides={
                    "device_processor": {"device": cfg.policy.device},
                    "rename_observations_processor": {"rename_map": cfg.dataset.rename_map},
                },
            )
        else:
            preprocessor, postprocessor = make_pre_post_processors(
                policy_cfg=cfg.policy,
                pretrained_path=cfg.policy.pretrained_path,
                dataset_stats=rename_stats(dataset.meta.stats, cfg.dataset.rename_map),
                preprocessor_overrides={
                    "device_processor": {"device": cfg.policy.device},
                    "rename_observations_processor": {"rename_map": cfg.dataset.rename_map},
                },
            )

    info = {}
    manager = VideoEncodingManager(dataset) if dataset is not None else nullcontext()
    with manager:
        recorded_episodes = 0
        while recorded_episodes < cfg.dataset.num_episodes and not info.get(TeleopEvents.STOP_RECORDING, False):

            # Execute a few seconds without recording to give time to manually reset the environment
            # Skip reset for the last episode to be recorded
            if teleop_on_reset and not info.get(TeleopEvents.INTERVENTION_COMPLETED, False):
                log_say("Reset the environment", cfg.play_sounds)

                info = record_loop(
                    env=env,
                    fps=cfg.dataset.fps,
                    control_time_s=cfg.env.processor.reset.reset_time_s,
                    action_dim=cfg.env.action_dim,
                    action_processor=action_processor,
                    env_processor=env_processor,
                    policy=None,
                    dataset=None,
                    display_data=cfg.display_data,
                    interactive=False
                )

            if info.get(TeleopEvents.STOP_RECORDING, False):
                break

            next_ep = (recorded_episodes + 1)
            log_say(f"Recording episode {next_ep}", cfg.play_sounds)
            
            # Get control time from env config if available, otherwise infinite
            episode_control_time = getattr(cfg.env.processor, "control_time_s", None) if hasattr(cfg.env, "processor") else None
            
            info = record_loop(
                env=env,
                fps=cfg.dataset.fps,
                action_dim=cfg.env.action_dim,
                action_processor=action_processor,
                env_processor=env_processor,
                policy=policy,
                preprocessor=preprocessor,
                postprocessor=postprocessor,
                dataset=dataset if not getattr(cfg, "demo_mode", False) else None,
                interactive=cfg.interactive,
                single_task=cfg.dataset.single_task,
                robot_type=cfg.env.type,
                display_data=cfg.display_data,
                control_time_s=episode_control_time,
            )

            if info.get(TeleopEvents.RERECORD_EPISODE, False):
                log_say("Re-record episode", cfg.play_sounds)
                if dataset is not None:
                    dataset.clear_episode_buffer()
                continue

            if getattr(cfg, "demo_mode", False):
                # In demo mode, complete the episode without saving
                recorded_episodes += 1
                continue
            else:
                if dataset.episode_buffer["size"] > 0:
                    dataset.save_episode()
                    recorded_episodes += 1
                    continue

            if info.get(TeleopEvents.STOP_RECORDING, False):
                break

            if dataset is not None and dataset.episode_buffer["size"] == 0:
                log_say("Dataset is empty, re-record episode", cfg.play_sounds)

    log_say("Stop recording", cfg.play_sounds, blocking=True)

    env.close()

    if dataset is not None and cfg.dataset.push_to_hub and not getattr(cfg, "demo_mode", False):
        dataset.push_to_hub(tags=cfg.dataset.tags, private=cfg.dataset.private)

    log_say("Exiting", cfg.play_sounds)
    return dataset


if __name__ == "__main__":
    import experiments
    record()
